{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier,VotingClassifier,BaggingClassifier,ExtraTreesClassifier,GradientBoostingClassifier,BaggingClassifier,ExtraTreesClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82657, 12)\n",
      "(20665, 11)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_name', 'country', 'review_title', 'review_description',\n",
       "       'designation', 'points', 'price', 'province', 'region_1', 'region_2',\n",
       "       'winery', 'variety'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_name', 'country', 'review_title', 'review_description',\n",
       "       'designation', 'points', 'price', 'province', 'region_1', 'region_2',\n",
       "       'winery'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>We need to predict the 'variety'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Looking over data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>country</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>winery</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Andrew Peace 2007 Peace Family Vineyard Chardo...</td>\n",
       "      <td>Classic Chardonnay aromas of apple, pear and h...</td>\n",
       "      <td>Peace Family Vineyard</td>\n",
       "      <td>83</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Australia Other</td>\n",
       "      <td>South Eastern Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andrew Peace</td>\n",
       "      <td>Chardonnay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@wawinereport</td>\n",
       "      <td>US</td>\n",
       "      <td>North by Northwest 2014 Red (Columbia Valley (...</td>\n",
       "      <td>This wine is near equal parts Syrah and Merlot...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Columbia Valley (WA)</td>\n",
       "      <td>Columbia Valley</td>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>Red Blend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_name    country  \\\n",
       "0            NaN  Australia   \n",
       "1  @wawinereport         US   \n",
       "\n",
       "                                        review_title  \\\n",
       "0  Andrew Peace 2007 Peace Family Vineyard Chardo...   \n",
       "1  North by Northwest 2014 Red (Columbia Valley (...   \n",
       "\n",
       "                                  review_description            designation  \\\n",
       "0  Classic Chardonnay aromas of apple, pear and h...  Peace Family Vineyard   \n",
       "1  This wine is near equal parts Syrah and Merlot...                    NaN   \n",
       "\n",
       "   points  price         province                 region_1         region_2  \\\n",
       "0      83   10.0  Australia Other  South Eastern Australia              NaN   \n",
       "1      89   15.0       Washington     Columbia Valley (WA)  Columbia Valley   \n",
       "\n",
       "               winery     variety  \n",
       "0        Andrew Peace  Chardonnay  \n",
       "1  North by Northwest   Red Blend  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>country</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>US</td>\n",
       "      <td>Boedecker Cellars 2011 Athena Pinot Noir (Will...</td>\n",
       "      <td>Nicely differentiated from the companion Stewa...</td>\n",
       "      <td>Athena</td>\n",
       "      <td>88</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Boedecker Cellars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@wineschach</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Mendoza Vineyards 2012 Gran Reserva by Richard...</td>\n",
       "      <td>Charred, smoky, herbal aromas of blackberry tr...</td>\n",
       "      <td>Gran Reserva by Richard Bonvin</td>\n",
       "      <td>90</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Mendoza Province</td>\n",
       "      <td>Mendoza</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mendoza Vineyards</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_name    country                                       review_title  \\\n",
       "0  @paulgwine          US  Boedecker Cellars 2011 Athena Pinot Noir (Will...   \n",
       "1  @wineschach  Argentina  Mendoza Vineyards 2012 Gran Reserva by Richard...   \n",
       "\n",
       "                                  review_description  \\\n",
       "0  Nicely differentiated from the companion Stewa...   \n",
       "1  Charred, smoky, herbal aromas of blackberry tr...   \n",
       "\n",
       "                      designation  points  price          province  \\\n",
       "0                          Athena      88   35.0            Oregon   \n",
       "1  Gran Reserva by Richard Bonvin      90   60.0  Mendoza Province   \n",
       "\n",
       "            region_1           region_2             winery  \n",
       "0  Willamette Valley  Willamette Valley  Boedecker Cellars  \n",
       "1            Mendoza                NaN  Mendoza Vineyards  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of rows with user_name as Nan: 19393\n"
     ]
    }
   ],
   "source": [
    "print(\"No of rows with user_name as Nan:\",train['user_name'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Assumption: I'm treating the the rows with user_name:Nan to be a single customer.\n",
    "    For convenience I'm considering the user_name of those rows as @namit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of rows with user_name as Nan: 0\n"
     ]
    }
   ],
   "source": [
    "train['user_name'] = train['user_name'].fillna('@namit')\n",
    "print(\"No of rows with user_name as Nan:\", train['user_name'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['user_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of rows with user_name as Nan: 4738\n",
      "No of rows with user_name as Nan: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"No of rows with user_name as Nan:\",test['user_name'].isnull().sum())\n",
    "\n",
    "test['user_name'] = test['user_name'].fillna('@namit')\n",
    "print(\"No of rows with user_name as Nan:\", test['user_name'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test['user_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User present in train data but not in test data: ['@winewchristina']\n"
     ]
    }
   ],
   "source": [
    "a=train['user_name'].unique().tolist()\n",
    "b=test['user_name'].unique().tolist()\n",
    "\n",
    "print(\"User present in train data but not in test data:\",np.setdiff1d(a,b) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82657, 12)\n",
      "(82622, 12)\n"
     ]
    }
   ],
   "source": [
    "#OBSERVATION: Rows which has null in 'country' also has null values in other state/region columns.\n",
    "#dropping rows which has null as country value\n",
    "\n",
    "\n",
    "print(train.shape)\n",
    "\n",
    "train = train.dropna(axis=0, subset=['country'])\n",
    "test = test.dropna(axis=0, subset=['country'])\n",
    "\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['country'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Replacing the row with null values with certain values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I've checked the rows with null values before doing the replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"region_1\"].fillna(\"no_region_1\", inplace = True) \n",
    "test[\"region_1\"].fillna(\"no_region_1\", inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"region_2\"].fillna(\"no_region_2\", inplace = True) \n",
    "test[\"region_2\"].fillna(\"no_region_2\", inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"designation\"].fillna(\"no_designation\", inplace = True) \n",
    "test[\"designation\"].fillna(\"no_designation\", inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82622, 12)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Handling the Nan values in 'price' colummn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    77057.000000\n",
       "mean        36.927093\n",
       "std         43.706034\n",
       "min          4.000000\n",
       "25%         18.000000\n",
       "50%         27.000000\n",
       "75%         45.000000\n",
       "max       3300.000000\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['price'].describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) min value= 4\n",
    "#2) max value seems like an outlier. let's check.\n",
    "#3) for now, considering null value to be 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"price\"].fillna(0, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 percentile value is 0.0\n",
      "10 percentile value is 10.0\n",
      "20 percentile value is 14.0\n",
      "30 percentile value is 17.0\n",
      "40 percentile value is 20.0\n",
      "50 percentile value is 25.0\n",
      "60 percentile value is 30.0\n",
      "70 percentile value is 39.0\n",
      "80 percentile value is 49.0\n",
      "90 percentile value is 65.0\n",
      "100 percentile value is  3300.0\n"
     ]
    }
   ],
   "source": [
    "#calculating 0-100th percentile to find a the correct percentile value for removal of outliers\n",
    "for i in range(0,100,10):\n",
    "    var =train[\"price\"].values\n",
    "    var = np.sort(var,axis = None)\n",
    "    print(\"{} percentile value is {}\".format(i,var[int(len(var)*(float(i)/100))]))\n",
    "print (\"100 percentile value is \",var[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 percentile value is 65.0\n",
      "91 percentile value is 68.0\n",
      "92 percentile value is 70.0\n",
      "93 percentile value is 75.0\n",
      "94 percentile value is 80.0\n",
      "95 percentile value is 85.0\n",
      "96 percentile value is 90.0\n",
      "97 percentile value is 100.0\n",
      "98 percentile value is 125.0\n",
      "99 percentile value is 160.0\n",
      "100 percentile value is  3300.0\n"
     ]
    }
   ],
   "source": [
    "#calculating 90-100th percentile to find a the correct percentile value for removal of outliers\n",
    "for i in range(90,100):\n",
    "    var =train[\"price\"].values\n",
    "    var = np.sort(var,axis = None)\n",
    "    print(\"{} percentile value is {}\".format(i,var[int(len(var)*(float(i)/100))]))\n",
    "print (\"100 percentile value is \",var[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.0 percentile value is 160.0\n",
      "99.1 percentile value is 169.0\n",
      "99.2 percentile value is 175.0\n",
      "99.3 percentile value is 195.0\n",
      "99.4 percentile value is 200.0\n",
      "99.5 percentile value is 225.0\n",
      "99.6 percentile value is 250.0\n",
      "99.7 percentile value is 300.0\n",
      "99.8 percentile value is 360.0\n",
      "99.9 percentile value is 469.0\n",
      "100 percentile value is  3300.0\n"
     ]
    }
   ],
   "source": [
    "#calculating speed values at each percntile 99.0,99.1,99.2,99.3,99.4,99.5,99.6,99.7,99.8,99.9,100\n",
    "for i in np.arange(0.0, 1.0, 0.1):\n",
    "    var =train[\"price\"].values\n",
    "    var = np.sort(var,axis = None)\n",
    "    print(\"{} percentile value is {}\".format(99+i,var[int(len(var)*(float(99+i)/100))]))\n",
    "print(\"100 percentile value is \",var[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82622 no of rows before\n",
      "82558 no of rows after\n"
     ]
    }
   ],
   "source": [
    "#Conisidering row with price<=500\n",
    "prev_shape = train.shape[0]\n",
    "print(prev_shape,\"no of rows before\")\n",
    "\n",
    "train = train[train['price']<=500.0]\n",
    "\n",
    "new_shape = train.shape[0]\n",
    "print(new_shape,\"no of rows after\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train['price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing the rows with null values with the mean values of price\n",
    "train['price'] = train['price'].replace(0,int(mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82558, 12)\n",
      "(20661, 11)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Pre-processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    c_tr = [ctry.strip().replace('&','').replace('-',' ').replace('(','').replace(')','').replace(' ','_') for ctry in data]\n",
    "    \n",
    "    return c_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['p_country'] = preprocess(train['country'].values)\n",
    "test['p_country'] = preprocess(test['country'].values)\n",
    "\n",
    "train['p_designation'] = preprocess(train['designation'].values)\n",
    "test['p_designation'] = preprocess(test['designation'].values)\n",
    "\n",
    "train['p_province'] = preprocess(train['province'].values)\n",
    "test['p_province'] = preprocess(test['province'].values)\n",
    "\n",
    "train['p_region_1'] = preprocess(train['region_1'].values)\n",
    "test['p_region_1'] = preprocess(test['region_1'].values)\n",
    "\n",
    "train['p_region_2'] = preprocess(train['region_2'].values)\n",
    "test['p_region_2'] = preprocess(test['region_2'].values)\n",
    "\n",
    "train['p_winery'] = preprocess(train['winery'].values)\n",
    "test['p_winery'] = preprocess(test['winery'].values)\n",
    "\n",
    "train['p_variety'] = preprocess(train['variety'].values)\n",
    "\n",
    "\n",
    "train.drop(['country','designation','province','region_1','region_2','winery','variety'], axis=1, inplace=True)\n",
    "test.drop(['country','designation','province','region_1','region_2','winery'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82558, 12)\n",
      "(20661, 11)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Pre-processing Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/47091490/4084039\n",
    "import re\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/sebleier/554280\n",
    "# we are removing the words from the stop words list: 'no', 'nor', 'not'\n",
    "stopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    preprocessed = []\n",
    "    # tqdm is for printing the status bar\n",
    "    for sentance in tqdm(data):\n",
    "        sent = decontracted(sentance)\n",
    "        sent = sent.replace('\\\\r', ' ') \n",
    "        sent = sent.replace('\\\\\"', ' ')\n",
    "        sent = sent.replace('\\\\n', ' ')\n",
    "        sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "        # https://gist.github.com/sebleier/554280\n",
    "        sent = ' '.join(e for e in sent.split() if e.lower() not in stopwords)\n",
    "        preprocessed.append(sent.lower().strip())\n",
    "        \n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82558/82558 [00:11<00:00, 7252.95it/s]\n",
      "100%|██████████| 82558/82558 [00:03<00:00, 23484.90it/s]\n",
      "100%|██████████| 20661/20661 [00:02<00:00, 6991.11it/s]\n",
      "100%|██████████| 20661/20661 [00:01<00:00, 19493.44it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_essays_tr = preprocess_data(train['review_description'].values)\n",
    "preprocessed_title_tr = preprocess_data(train['review_title'].values)\n",
    "\n",
    "preprocessed_essays_te = preprocess_data(test['review_description'].values)\n",
    "preprocessed_title_te = preprocess_data(test['review_title'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['p_essay'] = preprocessed_essays_tr\n",
    "train['p_title'] = preprocessed_title_tr\n",
    "\n",
    "train.drop(['review_title','review_description'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "test['p_essay'] = preprocessed_essays_te\n",
    "test['p_title'] = preprocessed_title_te\n",
    "\n",
    "test.drop(['review_title','review_description'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>p_country</th>\n",
       "      <th>p_designation</th>\n",
       "      <th>p_province</th>\n",
       "      <th>p_region_1</th>\n",
       "      <th>p_region_2</th>\n",
       "      <th>p_winery</th>\n",
       "      <th>p_variety</th>\n",
       "      <th>p_essay</th>\n",
       "      <th>p_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@namit</td>\n",
       "      <td>83</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Peace_Family_Vineyard</td>\n",
       "      <td>Australia_Other</td>\n",
       "      <td>South_Eastern_Australia</td>\n",
       "      <td>no_region_2</td>\n",
       "      <td>Andrew_Peace</td>\n",
       "      <td>Chardonnay</td>\n",
       "      <td>classic chardonnay aromas apple pear hay lead ...</td>\n",
       "      <td>andrew peace 2007 peace family vineyard chardo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@wawinereport</td>\n",
       "      <td>89</td>\n",
       "      <td>15.0</td>\n",
       "      <td>US</td>\n",
       "      <td>no_designation</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Columbia_Valley_WA</td>\n",
       "      <td>Columbia_Valley</td>\n",
       "      <td>North_by_Northwest</td>\n",
       "      <td>Red_Blend</td>\n",
       "      <td>wine near equal parts syrah merlot balance cab...</td>\n",
       "      <td>north northwest 2014 red columbia valley wa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_name  points  price  p_country          p_designation  \\\n",
       "0         @namit      83   10.0  Australia  Peace_Family_Vineyard   \n",
       "1  @wawinereport      89   15.0         US         no_designation   \n",
       "\n",
       "        p_province               p_region_1       p_region_2  \\\n",
       "0  Australia_Other  South_Eastern_Australia      no_region_2   \n",
       "1       Washington       Columbia_Valley_WA  Columbia_Valley   \n",
       "\n",
       "             p_winery   p_variety  \\\n",
       "0        Andrew_Peace  Chardonnay   \n",
       "1  North_by_Northwest   Red_Blend   \n",
       "\n",
       "                                             p_essay  \\\n",
       "0  classic chardonnay aromas apple pear hay lead ...   \n",
       "1  wine near equal parts syrah merlot balance cab...   \n",
       "\n",
       "                                             p_title  \n",
       "0  andrew peace 2007 peace family vineyard chardo...  \n",
       "1        north northwest 2014 red columbia valley wa  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82558, 12)\n",
      "(20661, 11)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical Data:\n",
    "\n",
    "    1) user_name\n",
    "    2) country\n",
    "    3) designation\n",
    "    4) province\n",
    "    5) region_1\n",
    "    6) region_2\n",
    "    7) winery\n",
    "    8) variety\n",
    "        \n",
    "Numerical Data:\n",
    "\n",
    "    1) price\n",
    "    2) points\n",
    "\n",
    "Text Data:\n",
    "\n",
    "    1) review_title\n",
    "    2) review_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Encoding categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_bow_list=[]  #creating this for feature importance (latter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anneinvino', 'bkfiona', 'gordone_cellars', 'joecz', 'kerinokeefe', 'laurbuzz', 'mattkettmann', 'namit', 'paulgwine', 'suskostrzewa', 'vboone', 'vossroger', 'wawinereport', 'wineschach', 'winewchristina', 'worldwineguys']\n",
      "(82558, 16)\n",
      "(20661, 16)\n"
     ]
    }
   ],
   "source": [
    "# we use count vectorizer to convert the values into one hot encoded features\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train['user_name'].values)\n",
    "\n",
    "name_tr = vectorizer.transform(train['user_name'].values)\n",
    "name_te = vectorizer.transform(test['user_name'].values)\n",
    "\n",
    "feature_bow_list.extend(vectorizer.get_feature_names())\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "print(name_tr.shape)\n",
    "print(name_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['argentina', 'australia', 'austria', 'brazil', 'bulgaria', 'canada', 'chile', 'croatia', 'cyprus', 'czech_republic', 'england', 'france', 'georgia', 'germany', 'greece', 'hungary', 'india', 'israel', 'italy', 'lebanon', 'luxembourg', 'macedonia', 'mexico', 'moldova', 'morocco', 'new_zealand', 'peru', 'portugal', 'romania', 'serbia', 'slovenia', 'south_africa', 'spain', 'switzerland', 'turkey', 'ukraine', 'uruguay', 'us']\n",
      "(82558, 38)\n",
      "(20661, 38)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train['p_country'].values)\n",
    "\n",
    "country_tr = vectorizer.transform(train['p_country'].values)\n",
    "country_te = vectorizer.transform(test['p_country'].values)\n",
    "\n",
    "feature_bow_list.extend(vectorizer.get_feature_names())\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "print(country_tr.shape)\n",
    "print(country_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82558, 26445)\n",
      "(20661, 26445)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train['p_designation'].values)\n",
    "\n",
    "designation_tr = vectorizer.transform(train['p_designation'].values)\n",
    "designation_te = vectorizer.transform(test['p_designation'].values)\n",
    "\n",
    "feature_bow_list.extend(vectorizer.get_feature_names())\n",
    "\n",
    "#print(vectorizer.get_feature_names())\n",
    "print(designation_tr.shape)\n",
    "print(designation_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82558, 359)\n",
      "(20661, 359)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train['p_province'].values)\n",
    "\n",
    "province_tr = vectorizer.transform(train['p_province'].values)\n",
    "province_te = vectorizer.transform(test['p_province'].values)\n",
    "\n",
    "feature_bow_list.extend(vectorizer.get_feature_names())\n",
    "\n",
    "#print(vectorizer.get_feature_names())\n",
    "print(province_tr.shape)\n",
    "print(province_te.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82558, 1036)\n",
      "(20661, 1036)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train['p_region_1'].values)\n",
    "\n",
    "region_1_tr = vectorizer.transform(train['p_region_1'].values)\n",
    "region_1_te = vectorizer.transform(test['p_region_1'].values)\n",
    "\n",
    "feature_bow_list.extend(vectorizer.get_feature_names())\n",
    "\n",
    "#print(vectorizer.get_feature_names())\n",
    "print(region_1_tr.shape)\n",
    "print(region_1_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82558, 18)\n",
      "(20661, 18)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train['p_region_2'].values)\n",
    "\n",
    "region_2_tr = vectorizer.transform(train['p_region_2'].values)\n",
    "region_2_te = vectorizer.transform(test['p_region_2'].values)\n",
    "\n",
    "feature_bow_list.extend(vectorizer.get_feature_names())\n",
    "\n",
    "#print(vectorizer.get_feature_names())\n",
    "print(region_2_tr.shape)\n",
    "print(region_2_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82558, 13925)\n",
      "(20661, 13925)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train['p_winery'].values)\n",
    "\n",
    "winery_tr = vectorizer.transform(train['p_winery'].values)\n",
    "winery_te = vectorizer.transform(test['p_winery'].values)\n",
    "\n",
    "feature_bow_list.extend(vectorizer.get_feature_names())\n",
    "\n",
    "#print(vectorizer.get_feature_names())\n",
    "print(winery_tr.shape)\n",
    "print(winery_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Encoding Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_bow_list.extend(['price','points'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82558, 1)\n",
      "(20661, 1)\n"
     ]
    }
   ],
   "source": [
    "test['price'] = test['price'].fillna(0)\n",
    "\n",
    "scalar = Normalizer()\n",
    "scalar.fit(train['price'].values.reshape(1,-1))\n",
    "\n",
    "price_train = scalar.transform(train['price'].values.reshape(1,-1)).reshape(-1,1)\n",
    "price_test = scalar.transform(test['price'].values.reshape(1,-1)).reshape(-1,1)\n",
    "\n",
    "print(price_train.shape)\n",
    "print(price_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82558, 1)\n",
      "(20661, 1)\n"
     ]
    }
   ],
   "source": [
    "scalar = Normalizer()\n",
    "scalar.fit(train['points'].values.reshape(1,-1))\n",
    "\n",
    "points_train = scalar.transform(train['points'].values.reshape(1,-1)).reshape(-1,1)\n",
    "points_test = scalar.transform(test['points'].values.reshape(1,-1)).reshape(-1,1)\n",
    "\n",
    "print(points_train.shape)\n",
    "print(points_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Encoding Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrix after one hot encodig  (82558, 7177)\n",
      "Shape of matrix after one hot encodig  (20661, 7177)\n"
     ]
    }
   ],
   "source": [
    "#BOW essay\n",
    "# We are considering only the words which appeared in at least 10 documents(rows or projects).\n",
    "vectorizer = CountVectorizer(min_df=10)\n",
    "vectorizer.fit(train['p_essay']) #fit\n",
    "\n",
    "essay_bow_train = vectorizer.transform(train['p_essay']) #transform\n",
    "essay_bow_test = vectorizer.transform(test['p_essay']) #transform\n",
    "\n",
    "feature_bow_list.extend(vectorizer.get_feature_names())\n",
    "\n",
    "\n",
    "print(\"Shape of matrix after one hot encodig \",essay_bow_train.shape)\n",
    "print(\"Shape of matrix after one hot encodig \",essay_bow_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrix after one hot encodig  (82558, 5040)\n",
      "Shape of matrix after one hot encodig  (20661, 5040)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=10)\n",
    "vectorizer.fit(train['p_title']) #fit\n",
    "\n",
    "title_bow_train = vectorizer.transform(train['p_title']) #transform\n",
    "title_bow_test = vectorizer.transform(test['p_title']) #transform\n",
    "\n",
    "feature_bow_list.extend(vectorizer.get_feature_names())\n",
    "\n",
    "\n",
    "print(\"Shape of matrix after one hot encodig \",title_bow_train.shape)\n",
    "print(\"Shape of matrix after one hot encodig \",title_bow_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrix after one hot encodig  (82558, 7177)\n",
      "Shape of matrix after one hot encodig  (20661, 7177)\n"
     ]
    }
   ],
   "source": [
    "#tf-idf essay\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=10)\n",
    "vectorizer.fit(train['p_essay']) #fit\n",
    "\n",
    "essay_tfidf_train = vectorizer.transform(train['p_essay']) #transform\n",
    "essay_tfidf_test = vectorizer.transform(test['p_essay']) #transform\n",
    "\n",
    "\n",
    "print(\"Shape of matrix after one hot encodig \",essay_tfidf_train.shape)\n",
    "print(\"Shape of matrix after one hot encodig \",essay_tfidf_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrix after one hot encodig  (82558, 5040)\n",
      "Shape of matrix after one hot encodig  (20661, 5040)\n"
     ]
    }
   ],
   "source": [
    "#tfidf title \n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=10)\n",
    "vectorizer.fit(train['p_title']) #fit\n",
    "\n",
    "title_tfidf_train = vectorizer.transform(train['p_title']) #transform\n",
    "title_tfidf_test = vectorizer.transform(test['p_title']) #transform\n",
    "\n",
    "\n",
    "print(\"Shape of matrix after one hot encodig \",title_tfidf_train.shape)\n",
    "print(\"Shape of matrix after one hot encodig \",title_tfidf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>average - W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:38, 10470.03it/s]\n"
     ]
    }
   ],
   "source": [
    "#loading pre-trained glove vectors\n",
    "import os\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('/Users/namitagarwal/Downloads/glove.6B/glove.6B.300d.txt'), encoding='utf8')\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_words = embeddings_index.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82558/82558 [00:08<00:00, 10031.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82558\n",
      "300\n",
      "(82558, 300)\n"
     ]
    }
   ],
   "source": [
    "# average Word2Vec for train(essay)\n",
    "# compute average word2vec for each review.\n",
    "avg_w2v_vectors_essay_train = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sentence in tqdm(train['p_essay']): # for each review/sentence\n",
    "    vector = np.zeros(300) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sentence.split(): # for each word in a review/sentence\n",
    "        if word in glove_words:\n",
    "            vector += embeddings_index[word]\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        vector /= cnt_words #calculatig (w2v(word_i))/(number of words in that sentence)\n",
    "    avg_w2v_vectors_essay_train.append(vector) #stores the w2v for all sentences/reviews in the entire dataset\n",
    "\n",
    "print(len(avg_w2v_vectors_essay_train))\n",
    "print(len(avg_w2v_vectors_essay_train[0]))\n",
    "\n",
    "avg_w2v_vectors_essay_train = np.array(avg_w2v_vectors_essay_train)\n",
    "print(avg_w2v_vectors_essay_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20661/20661 [00:01<00:00, 11121.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20661\n",
      "300\n",
      "(20661, 300)\n"
     ]
    }
   ],
   "source": [
    "# average Word2Vec for test(essay)\n",
    "# compute average word2vec for each review.\n",
    "avg_w2v_vectors_essay_test = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sentence in tqdm(test['p_essay']): # for each review/sentence\n",
    "    vector = np.zeros(300) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sentence.split(): # for each word in a review/sentence\n",
    "        if word in glove_words:\n",
    "            vector += embeddings_index[word]\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        vector /= cnt_words #calculatig (w2v(word_i))/(number of words in that sentence)\n",
    "    avg_w2v_vectors_essay_test.append(vector) #stores the w2v for all sentences/reviews in the entire dataset\n",
    "\n",
    "print(len(avg_w2v_vectors_essay_test))\n",
    "print(len(avg_w2v_vectors_essay_test[0]))\n",
    "\n",
    "avg_w2v_vectors_essay_test = np.array(avg_w2v_vectors_essay_test)\n",
    "print(avg_w2v_vectors_essay_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82558/82558 [00:03<00:00, 23188.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82558\n",
      "300\n",
      "(82558, 300)\n"
     ]
    }
   ],
   "source": [
    "# average Word2Vec for train(title)\n",
    "# compute average word2vec for each review.\n",
    "avg_w2v_vectors_title_train = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sentence in tqdm(train['p_title']): # for each review/sentence\n",
    "    vector = np.zeros(300) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sentence.split(): # for each word in a review/sentence\n",
    "        if word in glove_words:\n",
    "            vector += embeddings_index[word]\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        vector /= cnt_words #calculatig (w2v(word_i))/(number of words in that sentence)\n",
    "    avg_w2v_vectors_title_train.append(vector) #stores the w2v for all sentences/reviews in the entire dataset\n",
    "\n",
    "print(len(avg_w2v_vectors_title_train))\n",
    "print(len(avg_w2v_vectors_title_train[0]))\n",
    "\n",
    "avg_w2v_vectors_title_train = np.array(avg_w2v_vectors_title_train)\n",
    "print(avg_w2v_vectors_title_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20661/20661 [00:00<00:00, 30642.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20661\n",
      "300\n",
      "(20661, 300)\n"
     ]
    }
   ],
   "source": [
    "# average Word2Vec for test(title)\n",
    "# compute average word2vec for each review.\n",
    "avg_w2v_vectors_title_test = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sentence in tqdm(test['p_title']): # for each review/sentence\n",
    "    vector = np.zeros(300) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sentence.split(): # for each word in a review/sentence\n",
    "        if word in glove_words:\n",
    "            vector += embeddings_index[word]\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        vector /= cnt_words #calculatig (w2v(word_i))/(number of words in that sentence)\n",
    "    avg_w2v_vectors_title_test.append(vector) #stores the w2v for all sentences/reviews in the entire dataset\n",
    "\n",
    "print(len(avg_w2v_vectors_title_test))\n",
    "print(len(avg_w2v_vectors_title_test[0]))\n",
    "\n",
    "avg_w2v_vectors_title_test = np.array(avg_w2v_vectors_title_test)\n",
    "print(avg_w2v_vectors_title_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>tfidf-w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf-w2v ESSAY\n",
    "tfidf_model = TfidfVectorizer()\n",
    "tfidf_model.fit(train['p_essay'])\n",
    "# we are converting a dictionary with word as a key, and the idf as a value\n",
    "dictionary = dict(zip(tfidf_model.get_feature_names(), list(tfidf_model.idf_)))\n",
    "tfidf_words = set(tfidf_model.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82558/82558 [00:27<00:00, 2961.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82558\n",
      "300\n",
      "(82558, 300)\n"
     ]
    }
   ],
   "source": [
    "tfidf_w2v_vectors_essay_train = [] # the avg-w2v for each sentence/review is stored in this list\n",
    "for sentence in tqdm(train['p_essay']): # for each review/sentence\n",
    "    vector = np.zeros(300) # as word vectors are of zero length\n",
    "    tf_idf_weight =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sentence.split(): # for each word in a review/sentence\n",
    "        if (word in glove_words) and (word in tfidf_words):\n",
    "            vec = embeddings_index[word] # getting the vector for each word\n",
    "            # here we are multiplying idf value(dictionary[word]) and the tf value((sentence.count(word)/len(sentence.split())))\n",
    "            tf_idf = dictionary[word]*(sentence.count(word)/len(sentence.split())) # getting the tfidf value for each word\n",
    "            vector += (vec * tf_idf) # calculating tfidf weighted w2v\n",
    "            tf_idf_weight += tf_idf\n",
    "    if tf_idf_weight != 0:\n",
    "        vector /= tf_idf_weight\n",
    "    tfidf_w2v_vectors_essay_train.append(vector)\n",
    "\n",
    "print(len(tfidf_w2v_vectors_essay_train))\n",
    "print(len(tfidf_w2v_vectors_essay_train[0]))\n",
    "\n",
    "tfidf_w2v_vectors_essay_train = np.array(tfidf_w2v_vectors_essay_train)\n",
    "print(tfidf_w2v_vectors_essay_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20661/20661 [00:07<00:00, 2923.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20661\n",
      "300\n",
      "(20661, 300)\n"
     ]
    }
   ],
   "source": [
    "tfidf_w2v_vectors_essay_test = [] # the avg-w2v for each sentence/review is stored in this list\n",
    "for sentence in tqdm(test['p_essay']): # for each review/sentence\n",
    "    vector = np.zeros(300) # as word vectors are of zero length\n",
    "    tf_idf_weight =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sentence.split(): # for each word in a review/sentence\n",
    "        if (word in glove_words) and (word in tfidf_words):\n",
    "            vec = embeddings_index[word] # getting the vector for each word\n",
    "            # here we are multiplying idf value(dictionary[word]) and the tf value((sentence.count(word)/len(sentence.split())))\n",
    "            tf_idf = dictionary[word]*(sentence.count(word)/len(sentence.split())) # getting the tfidf value for each word\n",
    "            vector += (vec * tf_idf) # calculating tfidf weighted w2v\n",
    "            tf_idf_weight += tf_idf\n",
    "    if tf_idf_weight != 0:\n",
    "        vector /= tf_idf_weight\n",
    "    tfidf_w2v_vectors_essay_test.append(vector)\n",
    "\n",
    "print(len(tfidf_w2v_vectors_essay_test))\n",
    "print(len(tfidf_w2v_vectors_essay_test[0]))\n",
    "\n",
    "tfidf_w2v_vectors_essay_test = np.array(tfidf_w2v_vectors_essay_test)\n",
    "print(tfidf_w2v_vectors_essay_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf-w2v title\n",
    "tfidf_model = TfidfVectorizer()\n",
    "tfidf_model.fit(train['p_title'])\n",
    "# we are converting a dictionary with word as a key, and the idf as a value\n",
    "dictionary = dict(zip(tfidf_model.get_feature_names(), list(tfidf_model.idf_)))\n",
    "tfidf_words = set(tfidf_model.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82558/82558 [00:07<00:00, 11774.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82558\n",
      "300\n",
      "(82558, 300)\n"
     ]
    }
   ],
   "source": [
    "tfidf_w2v_vectors_title_train = [] # the avg-w2v for each sentence/review is stored in this list\n",
    "for sentence in tqdm(train['p_title']): # for each review/sentence\n",
    "    vector = np.zeros(300) # as word vectors are of zero length\n",
    "    tf_idf_weight =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sentence.split(): # for each word in a review/sentence\n",
    "        if (word in glove_words) and (word in tfidf_words):\n",
    "            vec = embeddings_index[word] # getting the vector for each word\n",
    "            # here we are multiplying idf value(dictionary[word]) and the tf value((sentence.count(word)/len(sentence.split())))\n",
    "            tf_idf = dictionary[word]*(sentence.count(word)/len(sentence.split())) # getting the tfidf value for each word\n",
    "            vector += (vec * tf_idf) # calculating tfidf weighted w2v\n",
    "            tf_idf_weight += tf_idf\n",
    "    if tf_idf_weight != 0:\n",
    "        vector /= tf_idf_weight\n",
    "    tfidf_w2v_vectors_title_train.append(vector)\n",
    "\n",
    "print(len(tfidf_w2v_vectors_title_train))\n",
    "print(len(tfidf_w2v_vectors_title_train[0]))\n",
    "\n",
    "tfidf_w2v_vectors_title_train = np.array(tfidf_w2v_vectors_title_train)\n",
    "print(tfidf_w2v_vectors_title_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20661/20661 [00:01<00:00, 13571.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20661\n",
      "300\n",
      "(20661, 300)\n"
     ]
    }
   ],
   "source": [
    "tfidf_w2v_vectors_title_test = [] # the avg-w2v for each sentence/review is stored in this list\n",
    "for sentence in tqdm(test['p_title']): # for each review/sentence\n",
    "    vector = np.zeros(300) # as word vectors are of zero length\n",
    "    tf_idf_weight =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sentence.split(): # for each word in a review/sentence\n",
    "        if (word in glove_words) and (word in tfidf_words):\n",
    "            vec = embeddings_index[word] # getting the vector for each word\n",
    "            # here we are multiplying idf value(dictionary[word]) and the tf value((sentence.count(word)/len(sentence.split())))\n",
    "            tf_idf = dictionary[word]*(sentence.count(word)/len(sentence.split())) # getting the tfidf value for each word\n",
    "            vector += (vec * tf_idf) # calculating tfidf weighted w2v\n",
    "            tf_idf_weight += tf_idf\n",
    "    if tf_idf_weight != 0:\n",
    "        vector /= tf_idf_weight\n",
    "    tfidf_w2v_vectors_title_test.append(vector)\n",
    "\n",
    "print(len(tfidf_w2v_vectors_title_test))\n",
    "print(len(tfidf_w2v_vectors_title_test[0]))\n",
    "\n",
    "tfidf_w2v_vectors_title_test = np.array(tfidf_w2v_vectors_title_test)\n",
    "print(tfidf_w2v_vectors_title_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Combining Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BOW\n",
    "x_bow_train = hstack((name_tr,country_tr,designation_tr,province_tr,region_1_tr,region_2_tr,winery_tr,price_train,points_train,essay_bow_train,title_bow_train))\n",
    "x_bow_test = hstack((name_te,country_te,designation_te,province_te,region_1_te,region_2_te,winery_te,price_test,points_test,essay_bow_test,title_bow_test))\n",
    "\n",
    "#TFIDF\n",
    "x_tfidf_train = hstack((name_tr,country_tr,designation_tr,province_tr,region_1_tr,region_2_tr,winery_tr,price_train,points_train,essay_tfidf_train,title_tfidf_train))\n",
    "x_tfidf_test = hstack((name_te,country_te,designation_te,province_te,region_1_te,region_2_te,winery_te,price_test,points_test,essay_tfidf_test,title_tfidf_test))\n",
    "\n",
    "#avg-w2v\n",
    "x_w2v_train = hstack((name_tr,country_tr,designation_tr,province_tr,region_1_tr,region_2_tr,winery_tr,price_train,points_train,avg_w2v_vectors_essay_train,avg_w2v_vectors_title_train))\n",
    "x_w2v_test = hstack((name_te,country_te,designation_te,province_te,region_1_te,region_2_te,winery_te,price_test,points_test,avg_w2v_vectors_essay_test,avg_w2v_vectors_title_test))\n",
    "\n",
    "#tfidf-w2v\n",
    "x_tfidf_w2v_train = hstack((name_tr,country_tr,designation_tr,province_tr,region_1_tr,region_2_tr,winery_tr,price_train,points_train,tfidf_w2v_vectors_essay_train,tfidf_w2v_vectors_title_train))\n",
    "x_tfidf_w2v_test = hstack((name_te,country_te,designation_te,province_te,region_1_te,region_2_te,winery_te,price_test,points_test,tfidf_w2v_vectors_essay_test,tfidf_w2v_vectors_title_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82558, 54056)\n",
      "(20661, 54056)\n",
      "(82558, 54056)\n",
      "(20661, 54056)\n",
      "(82558, 42439)\n",
      "(20661, 42439)\n",
      "(82558, 42439)\n",
      "(20661, 42439)\n"
     ]
    }
   ],
   "source": [
    "print(x_bow_train.shape)\n",
    "print(x_bow_test.shape)\n",
    "\n",
    "print(x_tfidf_train.shape)\n",
    "print(x_tfidf_test.shape)\n",
    "\n",
    "print(x_w2v_train.shape)\n",
    "print(x_w2v_test.shape)\n",
    "\n",
    "print(x_tfidf_w2v_train.shape)\n",
    "print(x_tfidf_w2v_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54056"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_bow_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Encoding y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82558,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "vectorizer = LabelEncoder()\n",
    "vectorizer.fit(train['p_variety'].values)\n",
    "\n",
    "variety_Y = vectorizer.transform(train['p_variety'].values)\n",
    "\n",
    "#print(vectorizer.get_feature_names())\n",
    "print(variety_Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 17, 11, ...,  6,  0,  3])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variety_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseliner(train, y, cv=3, metric='accuracy'):\n",
    "    \"\"\"\n",
    "    Function for baselining Models which return CV Score, Train Score, Valid Score\n",
    "    \"\"\"\n",
    "    print(\"Baseliner Models\\n\")\n",
    "    eval_dict = {}\n",
    "    models = [KNeighborsClassifier(),LogisticRegression(),MultinomialNB(),DecisionTreeClassifier(),RandomForestClassifier(),\n",
    "                lgb.LGBMClassifier(), xgb.XGBClassifier()]\n",
    "              \n",
    "             \n",
    "    print(\"Model Name \\t |   CV\")\n",
    "    print(\"--\" * 50)\n",
    "\n",
    "    for index, model in enumerate(models, 0):\n",
    "        model_name = str(model).split(\"(\")[0]\n",
    "        eval_dict[model_name] = {}\n",
    "\n",
    "        results = cross_val_score(model, train, y, cv=cv, scoring=metric)\n",
    "        eval_dict[model_name]['cv'] = results.mean()\n",
    "\n",
    "        print(\"%s \\t | %.4f \\t\" % (\n",
    "            model_name[:12], eval_dict[model_name]['cv']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> With BOW dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseliner Models\n",
      "\n",
      "Model Name \t |   CV\n",
      "----------------------------------------------------------------------------------------------------\n",
      "KNeighborsCl \t | 0.7967 \t\n",
      "LogisticRegr \t | 0.9766 \t\n",
      "MultinomialN \t | 0.8222 \t\n",
      "DecisionTree \t | 0.9696 \t\n",
      "RandomForest \t | 0.9020 \t\n",
      "LGBMClassifi \t | 0.9779 \t\n",
      "XGBClassifie \t | 0.9731 \t\n"
     ]
    }
   ],
   "source": [
    "baseliner(x_bow_train, variety_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> With tfidf dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseliner Models\n",
      "\n",
      "Model Name \t |   CV\n",
      "----------------------------------------------------------------------------------------------------\n",
      "KNeighborsCl \t | 0.6898 \t\n",
      "LogisticRegr \t | 0.9735 \t\n",
      "MultinomialN \t | 0.6802 \t\n",
      "DecisionTree \t | 0.9666 \t\n",
      "RandomForest \t | 0.8965 \t\n",
      "LGBMClassifi \t | 0.9764 \t\n",
      "XGBClassifie \t | 0.9722 \t\n"
     ]
    }
   ],
   "source": [
    "baseliner(x_tfidf_train, variety_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> The run time for avg w2v and tfidf-w2v was very high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> With avg w2v dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseliner(x_w2v_train, variety_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> With avg w2v-tfidf dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseliner(x_tfidf_w2v_train, variety_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Best Model + Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier()\n",
    "model.fit(x_bow_train, variety_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame(sorted(zip(model.feature_importances_,feature_bow_list)), columns=['Value','Feature'])\n",
    "\n",
    "#choosing top 20 features\n",
    "feature_imp = feature_imp.sort_values(by=['Value'],ascending=False)[:20] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp)#.sort_values(by=\"Value\", ascending=False))\n",
    "plt.title('LightGBM Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the bow and tfidf datasets - maximum accuracy on TRAIN data - was found to be <b>97.79%</b> using the <b>LGBMClassifier</b> using the bow dataset.\n",
    "\n",
    "\n",
    "<B>TO NOTE:</B>\n",
    "Before sending the model to production few things have to be noted-\n",
    "    1. There may be chances of Overfitting here, so the train data needs to be split into train and validation data and Overfitting/Underfitting has to be taken care by hyperparameter tuning. \n",
    "    2. Feature Engineering can be applied to improve accuracy.\n",
    "    \n",
    "<b>Feature Engineering: (to be checked)</b>\n",
    "    1. No. of reviews per customer/user_name\n",
    "    2. No.of reviews per - a.country \n",
    "                           b.designation\n",
    "                           c. province\n",
    "                           d. region_1\n",
    "                           e. region_2\n",
    "                           f. winery\n",
    "    3. Alot range for - a. price\n",
    "                        b. points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The data was looked over and attributes were studied.\n",
    "2. NaN values were handled\n",
    "3. Imputation was done for the missing price values where I imputed the missing values with the mean value of the dataset.\n",
    "4. Data Preprocessing was done.\n",
    "5. Categorical, Numerical and Text Data were encoded and stacked together in a horizontal stack.\n",
    "6. Various models were trained on these hstack data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
